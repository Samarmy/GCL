{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65ab5bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faiss library not found!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(1, os.path.join(sys.path[0], \"..\"))\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from argparse import ArgumentParser\n",
    "import torch\n",
    "\n",
    "import data_utils.utils as data_utils\n",
    "import inference.utils as inference_utils\n",
    "import BigGAN_PyTorch.utils as biggan_utils\n",
    "from data_utils.datasets_common import pil_loader\n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from glob import glob\n",
    "import utils\n",
    "import os\n",
    "from PIL import Image\n",
    "from data_utils.resnet import resnet50\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "from metrics import metric_utils\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ebd865d-6042-4157-8513-8f5375f15188",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitty = 1\n",
    "torch.cuda.set_device(splitty)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(splitty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2da7a7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(exp_name, root_path, backbone, device=\"cuda\"):\n",
    "    \n",
    "    parser = biggan_utils.prepare_parser()\n",
    "    parser = biggan_utils.add_sample_parser(parser)\n",
    "    parser = inference_utils.add_backbone_parser(parser)\n",
    "\n",
    "    args = [\"--experiment_name\", exp_name]\n",
    "    args += [\"--base_root\", root_path]\n",
    "    args += [\"--model_backbone\", backbone]\n",
    "\n",
    "    config = vars(parser.parse_args(args=args))\n",
    "\n",
    "    # Load model and overwrite configuration parameters if stored in the model\n",
    "    config = biggan_utils.update_config_roots(config, change_weight_folder=False)\n",
    "    generator, config = inference_utils.load_model_inference(config, device=device)\n",
    "    biggan_utils.count_parameters(generator)\n",
    "    generator.eval()\n",
    "\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae0c4b6a-de2b-4f17-8f70-a3af626d6ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = utils.load_pretrained_feature_extractor(\n",
    "#         '/Work2/Watch_This/ICGAN/ic_gan/pretrained_models_path/swav_800ep_pretrain.pth.tar',\n",
    "#         \"selfsupervised\",\n",
    "#         \"resnet50\",\n",
    "#     )\n",
    "# # net = torch.nn.DataParallel(net)\n",
    "# net.to(\"cuda\")\n",
    "# net.eval()\n",
    "# norm_mean = torch.Tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1).to(\"cuda\")\n",
    "# norm_std = torch.Tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d0621d5-890a-4e09-8e6a-affc3ffe3a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pegging all root folders to base root /Work2/Watch_This/ICGAN/ic_gan/pretrained_models_path\n",
      "For name best  best0  we have an FID:  22.453704833984375\n",
      "Checkpoint with name  best1  not in folder.\n",
      "Final name selected is  best0\n",
      "Loading best0 weights from /Work2/Watch_This/ICGAN/ic_gan/pretrained_models_path/icgan_biggan_imagenet_res256...\n",
      "Experiment name is icgan_biggan_imagenet_res256\n",
      "Adding attention layer in G at resolution 64\n",
      "Param count for Gs initialized parameters: 90014147\n",
      "Loading weights...\n",
      "Loading best0 weights from /Work2/Watch_This/ICGAN/ic_gan/pretrained_models_path/icgan_biggan_imagenet_res256...\n",
      "Putting G in eval mode..\n",
      "Number of parameters: 90014340\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (activation): ReLU()\n",
       "  (shared): Embedding(1000, 128)\n",
       "  (shared_feat): SNLinear(in_features=2048, out_features=512, bias=True)\n",
       "  (linear): SNLinear(in_features=17, out_features=24576, bias=True)\n",
       "  (blocks): ModuleList(\n",
       "    (0): ModuleList(\n",
       "      (0): GBlock(\n",
       "        (activation): ReLU()\n",
       "        (conv1): SNConv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): SNConv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv_sc): SNConv2d(1536, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): ccbn(\n",
       "          out: 1536, in: 529, cross_replica=False\n",
       "          (gain): SNLinear(in_features=529, out_features=1536, bias=False)\n",
       "          (bias): SNLinear(in_features=529, out_features=1536, bias=False)\n",
       "        )\n",
       "        (bn2): ccbn(\n",
       "          out: 1536, in: 529, cross_replica=False\n",
       "          (gain): SNLinear(in_features=529, out_features=1536, bias=False)\n",
       "          (bias): SNLinear(in_features=529, out_features=1536, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): ModuleList(\n",
       "      (0): GBlock(\n",
       "        (activation): ReLU()\n",
       "        (conv1): SNConv2d(1536, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): SNConv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv_sc): SNConv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): ccbn(\n",
       "          out: 1536, in: 529, cross_replica=False\n",
       "          (gain): SNLinear(in_features=529, out_features=1536, bias=False)\n",
       "          (bias): SNLinear(in_features=529, out_features=1536, bias=False)\n",
       "        )\n",
       "        (bn2): ccbn(\n",
       "          out: 768, in: 529, cross_replica=False\n",
       "          (gain): SNLinear(in_features=529, out_features=768, bias=False)\n",
       "          (bias): SNLinear(in_features=529, out_features=768, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): ModuleList(\n",
       "      (0): GBlock(\n",
       "        (activation): ReLU()\n",
       "        (conv1): SNConv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): SNConv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv_sc): SNConv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): ccbn(\n",
       "          out: 768, in: 529, cross_replica=False\n",
       "          (gain): SNLinear(in_features=529, out_features=768, bias=False)\n",
       "          (bias): SNLinear(in_features=529, out_features=768, bias=False)\n",
       "        )\n",
       "        (bn2): ccbn(\n",
       "          out: 768, in: 529, cross_replica=False\n",
       "          (gain): SNLinear(in_features=529, out_features=768, bias=False)\n",
       "          (bias): SNLinear(in_features=529, out_features=768, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): ModuleList(\n",
       "      (0): GBlock(\n",
       "        (activation): ReLU()\n",
       "        (conv1): SNConv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): SNConv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv_sc): SNConv2d(768, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): ccbn(\n",
       "          out: 768, in: 529, cross_replica=False\n",
       "          (gain): SNLinear(in_features=529, out_features=768, bias=False)\n",
       "          (bias): SNLinear(in_features=529, out_features=768, bias=False)\n",
       "        )\n",
       "        (bn2): ccbn(\n",
       "          out: 384, in: 529, cross_replica=False\n",
       "          (gain): SNLinear(in_features=529, out_features=384, bias=False)\n",
       "          (bias): SNLinear(in_features=529, out_features=384, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Attention(\n",
       "        (theta): SNConv2d(384, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (phi): SNConv2d(384, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (g): SNConv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (o): SNConv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (4): ModuleList(\n",
       "      (0): GBlock(\n",
       "        (activation): ReLU()\n",
       "        (conv1): SNConv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): SNConv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv_sc): SNConv2d(384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): ccbn(\n",
       "          out: 384, in: 529, cross_replica=False\n",
       "          (gain): SNLinear(in_features=529, out_features=384, bias=False)\n",
       "          (bias): SNLinear(in_features=529, out_features=384, bias=False)\n",
       "        )\n",
       "        (bn2): ccbn(\n",
       "          out: 192, in: 529, cross_replica=False\n",
       "          (gain): SNLinear(in_features=529, out_features=192, bias=False)\n",
       "          (bias): SNLinear(in_features=529, out_features=192, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): ModuleList(\n",
       "      (0): GBlock(\n",
       "        (activation): ReLU()\n",
       "        (conv1): SNConv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): SNConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv_sc): SNConv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): ccbn(\n",
       "          out: 192, in: 529, cross_replica=False\n",
       "          (gain): SNLinear(in_features=529, out_features=192, bias=False)\n",
       "          (bias): SNLinear(in_features=529, out_features=192, bias=False)\n",
       "        )\n",
       "        (bn2): ccbn(\n",
       "          out: 96, in: 529, cross_replica=False\n",
       "          (gain): SNLinear(in_features=529, out_features=96, bias=False)\n",
       "          (bias): SNLinear(in_features=529, out_features=96, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (output_layer): Sequential(\n",
       "    (0): bn()\n",
       "    (1): ReLU()\n",
       "    (2): SNConv2d(96, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_name = \"%s_%s_%s_res%i%s\" % (\n",
    "        \"icgan\",\n",
    "        \"biggan\",\n",
    "        \"imagenet\",\n",
    "        256,\n",
    "        \"\",\n",
    "    )\n",
    "generator = get_model(\n",
    "        exp_name, \"/Work2/Watch_This/ICGAN/ic_gan/pretrained_models_path\", \"biggan\"\n",
    "    )\n",
    "\n",
    "generator.cuda()\n",
    "generator.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32bdd0fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG16(\n",
       "  (layers): ModuleDict(\n",
       "    (conv1): Conv2dLayer()\n",
       "    (conv2): Conv2dLayer()\n",
       "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv3): Conv2dLayer()\n",
       "    (conv4): Conv2dLayer()\n",
       "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv5): Conv2dLayer()\n",
       "    (conv6): Conv2dLayer()\n",
       "    (conv7): Conv2dLayer()\n",
       "    (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv8): Conv2dLayer()\n",
       "    (conv9): Conv2dLayer()\n",
       "    (conv10): Conv2dLayer()\n",
       "    (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv11): Conv2dLayer()\n",
       "    (conv12): Conv2dLayer()\n",
       "    (conv13): Conv2dLayer()\n",
       "    (pool5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (fc1): FullyConnectedLayer()\n",
       "    (fc2): FullyConnectedLayer()\n",
       "    (fc3): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "    (softmax): Softmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "\n",
    "vgg16_url = 'https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/metrics/vgg16.pkl'\n",
    "vgg16 = metric_utils.get_feature_detector(vgg16_url, device=device)\n",
    "vgg16.cuda()\n",
    "vgg16.eval()\n",
    "\n",
    "exp_name = \"%s_%s_%s_res%i%s\" % (\n",
    "        \"icgan\",\n",
    "        \"biggan\",\n",
    "        \"imagenet\",\n",
    "        256,\n",
    "        \"\",\n",
    "    )\n",
    "generator = get_model(\n",
    "        exp_name, \"/Work2/Watch_This/ICGAN/ic_gan/pretrained_models_path\", \"biggan\", device=device\n",
    "    )\n",
    "\n",
    "generator.cuda()\n",
    "generator.eval()\n",
    "\n",
    "dataset = utils.get_dataset_images(\n",
    "        256,\n",
    "        data_path=\"/Work1/imagenet\",\n",
    "        longtail=False,\n",
    "        split=\"train\",\n",
    "        test_part=False,\n",
    "        which_dataset=\"imagenet\",\n",
    "        instance_json=\"\",\n",
    "        stuff_json=\"\",\n",
    "        get_encodings=True,\n",
    "    )\n",
    "\n",
    "generator1 = torch.Generator().manual_seed(42)\n",
    "dataset = torch.utils.data.random_split(dataset, [0.25, 0.25, 0.25, 0.25], generator=generator1)[splitty]\n",
    "\n",
    "loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=41,\n",
    "    num_workers=12,\n",
    "    pin_memory=True,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "num_steps = 100\n",
    "initial_learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8abe09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_60486/1051938831.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  z2 = torch.tensor(z1, dtype=torch.float32, device=gpu, requires_grad=True)\n",
      "/home/sarmst/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.012800819252432157\n",
      "0.025601638504864313\n"
     ]
    }
   ],
   "source": [
    "gpu = torch.device(\"cuda\")\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "for ind, data in enumerate(loader):\n",
    "    # if (((ind/len(loader))*100.0) < 34.35133770822817):\n",
    "    #     print(\"skipping\")\n",
    "    #     continue\n",
    "        \n",
    "    with torch.no_grad():\n",
    "#         start_time = time.time()\n",
    "        # data2 = data[0].cuda(gpu, non_blocking=True)\n",
    "        # x_tf1 = data2 * 0.5 + 0.5\n",
    "        # x_tf2 = (x_tf1 - norm_mean) / norm_std\n",
    "        # x_tf3 = torch.nn.functional.upsample(x_tf2, 224, mode=\"bicubic\")\n",
    "        # x_feat1, _ = net(x_tf3)\n",
    "        # x_feat2 =  x_feat1/torch.linalg.norm(x_feat1, dim=1, keepdims=True)\n",
    "\n",
    "        \n",
    "        path = data[3]\n",
    "        data0 = data[0].cuda(gpu, non_blocking=True)\n",
    "        x_feat2 =  data[4].cuda(gpu, non_blocking=True)\n",
    "\n",
    "        z1 = torch.zeros((data0.shape[0], 119)).cuda(gpu)\n",
    "        \n",
    "        x_img_orig = generator(z1, None, x_feat2)\n",
    "\n",
    "        target_img = torch.clamp((data0 * 0.5 + 0.5), 0, 1)*255\n",
    "        target_features = vgg16(F.interpolate(target_img, size=(224, 224)), resize_images=False, return_lpips=True)\n",
    "    \n",
    "    z2 = torch.tensor(z1, dtype=torch.float32, device=gpu, requires_grad=True)\n",
    "    \n",
    "    optimizer = torch.optim.Adam([z2], betas=(0.9, 0.999), lr=initial_learning_rate)\n",
    "    scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=0.1, total_iters=20)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        original_synth_image = generator(z2, None, x_feat2).cpu()\n",
    "    \n",
    "    for step in range(num_steps):          \n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            x_img = generator(z2, None, x_feat2)\n",
    "            synth_images = (x_img + 1) * (255/2)\n",
    "            synth_features = vgg16(F.interpolate(synth_images, size=(224, 224)), resize_images=False, return_lpips=True)\n",
    "            lpips_loss = (target_features - synth_features).square().sum(dim=1).sum()\n",
    "#             mse_loss = l2_criterion(target_img, synth_images)\n",
    "            loss = lpips_loss\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "        \n",
    "    with torch.no_grad():    \n",
    "        # x_img = generator(z2, None, x_feat2)\n",
    "        for ind3 in range(x_img.shape[0]):\n",
    "            folder = path[ind3].replace(\"imagenet\", \"ICGAN_Inversion\").replace(\".JPEG\", \"\")\n",
    "            os.makedirs(folder, exist_ok=True)\n",
    "            file_name = folder.split(\"/\")[-1]\n",
    "            original_image = Image.open(path[ind3]).convert(\"RGB\") \n",
    "            original_image.save(folder + \"/\" + file_name + \"_R.JPEG\")\n",
    "            _gen_img = torchvision.transforms.functional.to_pil_image(torch.clamp((x_img[ind3] * 0.5 + 0.5), 0, 1))\n",
    "            _gen_img.save(folder + \"/\" + file_name + \"_0_G.JPEG\")\n",
    "            _original_synth_image = torchvision.transforms.functional.to_pil_image(torch.clamp((original_synth_image[ind3] * 0.5 + 0.5), 0, 1))\n",
    "            _original_synth_image.save(folder + \"/\" + file_name + \"_1_G.JPEG\")\n",
    "    #         break\n",
    "    print((ind/len(loader))*100.0)\n",
    "    torch.save(((ind/len(loader))*100.0), \"Encoder_Inversion\" + str(splitty) + \"_Checkpoint.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b70cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3768f099-412a-45d0-bd8a-1aff884b8574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _original_synth_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa57fb4-bff8-4c1e-8850-324be27c9e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _gen_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7005ee61-effc-45dd-a15a-143a42044be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a0c7d1-3105-45ec-9eef-09578239c832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768c5415-5868-430c-a4fb-f44d377d585f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251b1684-45a6-41d1-b72a-52051a0bbf72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
