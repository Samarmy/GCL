{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0543b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faiss library not found!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(1, os.path.join(sys.path[0], \"..\"))\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from argparse import ArgumentParser\n",
    "import torch\n",
    "\n",
    "import data_utils.utils as data_utils\n",
    "import inference.utils as inference_utils\n",
    "import BigGAN_PyTorch.utils as biggan_utils\n",
    "from data_utils.datasets_common import pil_loader\n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f277ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from glob import glob\n",
    "import utils\n",
    "import os\n",
    "from PIL import Image\n",
    "from data_utils.resnet import resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2883fa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(root_path, model, resolution, which_dataset, visualize_instance_images):\n",
    "    data_path = os.path.join(root_path, \"stored_instances\")\n",
    "    if model == \"cc_icgan\":\n",
    "        feature_extractor = \"classification\"\n",
    "    else:\n",
    "        feature_extractor = \"selfsupervised\"\n",
    "    filename = \"%s_res%i_rn50_%s_kmeans_k1000_instance_features.npy\" % (\n",
    "        which_dataset,\n",
    "        resolution,\n",
    "        feature_extractor,\n",
    "    )\n",
    "    # Load conditioning instances from files\n",
    "    data = np.load(os.path.join(data_path, filename), allow_pickle=True).item()\n",
    "\n",
    "    transform_list = None\n",
    "    if visualize_instance_images:\n",
    "        # Transformation used for ImageNet images.\n",
    "        transform_list = transforms.Compose(\n",
    "            [data_utils.CenterCropLongEdge(), transforms.Resize(resolution)]\n",
    "        )\n",
    "    return data, transform_list\n",
    "\n",
    "\n",
    "def get_model(exp_name, root_path, backbone, device=\"cuda\"):\n",
    "    parser = biggan_utils.prepare_parser()\n",
    "    parser = biggan_utils.add_sample_parser(parser)\n",
    "    parser = inference_utils.add_backbone_parser(parser)\n",
    "\n",
    "    args = [\"--experiment_name\", exp_name]\n",
    "    args += [\"--base_root\", root_path]\n",
    "    args += [\"--model_backbone\", backbone]\n",
    "\n",
    "    config = vars(parser.parse_args(args=args))\n",
    "\n",
    "    # Load model and overwrite configuration parameters if stored in the model\n",
    "    config = biggan_utils.update_config_roots(config, change_weight_folder=False)\n",
    "    generator, config = inference_utils.load_model_inference(config, device=device)\n",
    "    biggan_utils.count_parameters(generator)\n",
    "    generator.eval()\n",
    "\n",
    "    return generator\n",
    "\n",
    "\n",
    "def get_conditionings(test_config, generator, data):\n",
    "    # Obtain noise vectors\n",
    "    z = torch.empty(\n",
    "        5 * 5,\n",
    "        generator.z_dim if \"biggan\" == \"stylegan2\" else generator.dim_z,\n",
    "    ).normal_(mean=0, std=1.0)\n",
    "\n",
    "    # Subsampling some instances from the 1000 k-means centers file\n",
    "    if 5 > 1:\n",
    "        total_idxs = np.random.choice(\n",
    "            range(1000), 5, replace=False\n",
    "        )\n",
    "\n",
    "    # Obtain features, labels and ground truth image paths\n",
    "    all_feats, all_img_paths, all_labels = [], [], []\n",
    "    for counter in range(5):\n",
    "        # Index in 1000 k-means centers file\n",
    "        if None is not None:\n",
    "            idx = None\n",
    "        else:\n",
    "            idx = total_idxs[counter]\n",
    "        # Image paths to visualize ground-truth instance\n",
    "        if False:\n",
    "            all_img_paths.append(data[\"image_path\"][idx])\n",
    "        # Instance features\n",
    "        all_feats.append(\n",
    "            torch.FloatTensor(data[\"instance_features\"][idx : idx + 1]).repeat(\n",
    "                5, 1\n",
    "            )\n",
    "        )\n",
    "        # Obtain labels\n",
    "        if None is not None:\n",
    "            # Swap label for a manually specified one\n",
    "            label_int = None\n",
    "        else:\n",
    "            # Use the label associated to the instance feature\n",
    "            label_int = int(data[\"labels\"][idx])\n",
    "        # Format labels according to the backbone\n",
    "        labels = None\n",
    "        if \"biggan\" == \"stylegan2\":\n",
    "            dim_labels = 1000\n",
    "            labels = torch.eye(dim_labels)[torch.LongTensor([label_int])].repeat(\n",
    "                5, 1\n",
    "            )\n",
    "        else:\n",
    "            if \"icgan\" == \"cc_icgan\":\n",
    "                labels = torch.LongTensor([label_int]).repeat(\n",
    "                    5\n",
    "                )\n",
    "        all_labels.append(labels)\n",
    "    # Concatenate all conditionings\n",
    "    all_feats = torch.cat(all_feats)\n",
    "    if all_labels[0] is not None:\n",
    "        all_labels = torch.cat(all_labels)\n",
    "    else:\n",
    "        all_labels = None\n",
    "    return z, all_feats, all_labels, all_img_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0fac1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using resnet50 to extract features\n",
      "Loading pretrained weights from:  /Work2/Watch_This/ICGAN/ic_gan/pretrained_models_path/swav_800ep_pretrain.pth.tar\n",
      "key  projection_head.0.weight  not in dict\n",
      "key  projection_head.0.bias  not in dict\n",
      "key  projection_head.1.weight  not in dict\n",
      "key  projection_head.1.bias  not in dict\n",
      "key  projection_head.1.running_mean  not in dict\n",
      "key  projection_head.1.running_var  not in dict\n",
      "key  projection_head.1.num_batches_tracked  not in dict\n",
      "key  projection_head.3.weight  not in dict\n",
      "key  projection_head.3.bias  not in dict\n",
      "key  prototypes.weight  not in dict\n",
      "Network key  fc.weight  not in dict to load\n",
      "Network key  fc.bias  not in dict to load\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): ResNet_mine(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = utils.load_pretrained_feature_extractor(\n",
    "        '/Work2/Watch_This/ICGAN/ic_gan/pretrained_models_path/swav_800ep_pretrain.pth.tar',\n",
    "        \"selfsupervised\",\n",
    "        \"resnet50\",\n",
    "    )\n",
    "net = torch.nn.DataParallel(net)\n",
    "net.to(\"cuda\")\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2af6f66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = utils.load_pretrained_feature_extractor(\n",
    "#         \"/Work2/Watch_This/ICGAN/ic_gan/pretrained_models_path/icgan_biggan_imagenet_res256/state_dict_best0.pth\",\n",
    "#         \"classification\",\n",
    "#         \"resnet50\",\n",
    "#     )\n",
    "# net  = net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d535b735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pegging all root folders to base root /Work2/Watch_This/ICGAN/ic_gan/pretrained_models_path\n",
      "For name best  best0  we have an FID:  22.453704833984375\n",
      "Checkpoint with name  best1  not in folder.\n",
      "Final name selected is  best0\n",
      "Loading best0 weights from /Work2/Watch_This/ICGAN/ic_gan/pretrained_models_path/icgan_biggan_imagenet_res256...\n",
      "Experiment name is icgan_biggan_imagenet_res256\n",
      "Adding attention layer in G at resolution 64\n",
      "Param count for Gs initialized parameters: 90014147\n",
      "Loading weights...\n",
      "Loading best0 weights from /Work2/Watch_This/ICGAN/ic_gan/pretrained_models_path/icgan_biggan_imagenet_res256...\n",
      "Putting G in eval mode..\n",
      "Number of parameters: 90014340\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): Generator(\n",
       "    (activation): ReLU()\n",
       "    (shared): Embedding(1000, 128)\n",
       "    (shared_feat): SNLinear(in_features=2048, out_features=512, bias=True)\n",
       "    (linear): SNLinear(in_features=17, out_features=24576, bias=True)\n",
       "    (blocks): ModuleList(\n",
       "      (0): ModuleList(\n",
       "        (0): GBlock(\n",
       "          (activation): ReLU()\n",
       "          (conv1): SNConv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv2): SNConv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_sc): SNConv2d(1536, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): ccbn(\n",
       "            out: 1536, in: 529, cross_replica=False\n",
       "            (gain): SNLinear(in_features=529, out_features=1536, bias=False)\n",
       "            (bias): SNLinear(in_features=529, out_features=1536, bias=False)\n",
       "          )\n",
       "          (bn2): ccbn(\n",
       "            out: 1536, in: 529, cross_replica=False\n",
       "            (gain): SNLinear(in_features=529, out_features=1536, bias=False)\n",
       "            (bias): SNLinear(in_features=529, out_features=1536, bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): ModuleList(\n",
       "        (0): GBlock(\n",
       "          (activation): ReLU()\n",
       "          (conv1): SNConv2d(1536, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv2): SNConv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_sc): SNConv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): ccbn(\n",
       "            out: 1536, in: 529, cross_replica=False\n",
       "            (gain): SNLinear(in_features=529, out_features=1536, bias=False)\n",
       "            (bias): SNLinear(in_features=529, out_features=1536, bias=False)\n",
       "          )\n",
       "          (bn2): ccbn(\n",
       "            out: 768, in: 529, cross_replica=False\n",
       "            (gain): SNLinear(in_features=529, out_features=768, bias=False)\n",
       "            (bias): SNLinear(in_features=529, out_features=768, bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): ModuleList(\n",
       "        (0): GBlock(\n",
       "          (activation): ReLU()\n",
       "          (conv1): SNConv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv2): SNConv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_sc): SNConv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): ccbn(\n",
       "            out: 768, in: 529, cross_replica=False\n",
       "            (gain): SNLinear(in_features=529, out_features=768, bias=False)\n",
       "            (bias): SNLinear(in_features=529, out_features=768, bias=False)\n",
       "          )\n",
       "          (bn2): ccbn(\n",
       "            out: 768, in: 529, cross_replica=False\n",
       "            (gain): SNLinear(in_features=529, out_features=768, bias=False)\n",
       "            (bias): SNLinear(in_features=529, out_features=768, bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): ModuleList(\n",
       "        (0): GBlock(\n",
       "          (activation): ReLU()\n",
       "          (conv1): SNConv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv2): SNConv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_sc): SNConv2d(768, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): ccbn(\n",
       "            out: 768, in: 529, cross_replica=False\n",
       "            (gain): SNLinear(in_features=529, out_features=768, bias=False)\n",
       "            (bias): SNLinear(in_features=529, out_features=768, bias=False)\n",
       "          )\n",
       "          (bn2): ccbn(\n",
       "            out: 384, in: 529, cross_replica=False\n",
       "            (gain): SNLinear(in_features=529, out_features=384, bias=False)\n",
       "            (bias): SNLinear(in_features=529, out_features=384, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (1): Attention(\n",
       "          (theta): SNConv2d(384, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (phi): SNConv2d(384, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (g): SNConv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (o): SNConv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (4): ModuleList(\n",
       "        (0): GBlock(\n",
       "          (activation): ReLU()\n",
       "          (conv1): SNConv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv2): SNConv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_sc): SNConv2d(384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): ccbn(\n",
       "            out: 384, in: 529, cross_replica=False\n",
       "            (gain): SNLinear(in_features=529, out_features=384, bias=False)\n",
       "            (bias): SNLinear(in_features=529, out_features=384, bias=False)\n",
       "          )\n",
       "          (bn2): ccbn(\n",
       "            out: 192, in: 529, cross_replica=False\n",
       "            (gain): SNLinear(in_features=529, out_features=192, bias=False)\n",
       "            (bias): SNLinear(in_features=529, out_features=192, bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): ModuleList(\n",
       "        (0): GBlock(\n",
       "          (activation): ReLU()\n",
       "          (conv1): SNConv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv2): SNConv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv_sc): SNConv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): ccbn(\n",
       "            out: 192, in: 529, cross_replica=False\n",
       "            (gain): SNLinear(in_features=529, out_features=192, bias=False)\n",
       "            (bias): SNLinear(in_features=529, out_features=192, bias=False)\n",
       "          )\n",
       "          (bn2): ccbn(\n",
       "            out: 96, in: 529, cross_replica=False\n",
       "            (gain): SNLinear(in_features=529, out_features=96, bias=False)\n",
       "            (bias): SNLinear(in_features=529, out_features=96, bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (output_layer): Sequential(\n",
       "      (0): bn()\n",
       "      (1): ReLU()\n",
       "      (2): SNConv2d(96, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "exp_name = \"%s_%s_%s_res%i%s\" % (\n",
    "        \"icgan\",\n",
    "        \"biggan\",\n",
    "        \"imagenet\",\n",
    "        256,\n",
    "        \"\",\n",
    "    )\n",
    "generator = get_model(\n",
    "        exp_name, \"/Work2/Watch_This/ICGAN/ic_gan/pretrained_models_path\", \"biggan\", device=device\n",
    "    )\n",
    "\n",
    "generator = torch.nn.DataParallel(generator)\n",
    "generator.to(\"cuda\")\n",
    "generator.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1387c370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feat_map0 = torch.load(\"/Work2/Watch_This/ICGAN/ic_gan/data_utils/test_images/0_feat_map.pth\").unsqueeze(0)\n",
    "# img0 = Image.open(\"/Work2/Watch_This/ICGAN/ic_gan/data_utils/test_images/0_img.JPEG\") \n",
    "# img0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3016ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# z = torch.normal(0.0, 0.0, (1, 119)) \n",
    "\n",
    "# out_img0 = generator(\n",
    "#             z[0:1].to(device), None, feat_map0.to(device)\n",
    "#         )\n",
    "# out_img0 = torch.clamp((out_img0 * 0.5 + 0.5), 0, 1)\n",
    "# torchvision.transforms.functional.to_pil_image(out_img0[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b84b9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feat_map1 = torch.load(\"/Work2/Watch_This/ICGAN/ic_gan/data_utils/test_images/1_feat_map.pth\").unsqueeze(0)\n",
    "# img1 = Image.open(\"/Work2/Watch_This/ICGAN/ic_gan/data_utils/test_images/1_img.JPEG\") \n",
    "# img1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb6bef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# z = torch.normal(0.0, 0.0, (1, 119)) \n",
    "\n",
    "# out_img1 = generator(\n",
    "#             z[0:1].to(device), None, feat_map1.to(device)\n",
    "#         )\n",
    "# out_img1 = torch.clamp((out_img1 * 0.5 + 0.5), 0, 1)\n",
    "# torchvision.transforms.functional.to_pil_image(out_img1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24d82156",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob(\"/Work1/imagenet/val/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e6ba9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    os.makedirs(file.replace(\"imagenet\", \"ICGAN\"), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f11b7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob(\"/Work1/imagenet/train/*/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd96534a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    os.makedirs(file.replace(\"imagenet\", \"ICGAN\").replace(\".JPEG\", \"\"), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b492cddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating  Index file imagenet_imgs.npz...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 2/2 [00:03<00:00,  1.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping last batch?  False\n",
      "Loader workers? {'num_workers': 32, 'pin_memory': True, 'drop_last': False}  with shuffle? False\n"
     ]
    }
   ],
   "source": [
    "dataset = utils.get_dataset_images(\n",
    "        256,\n",
    "        data_path=\"/Work1/imagenet\",\n",
    "        longtail=False,\n",
    "        split=\"train\",\n",
    "        test_part=False,\n",
    "        which_dataset=\"imagenet\",\n",
    "        instance_json=\"\",\n",
    "        stuff_json=\"\",\n",
    "    )\n",
    "\n",
    "kwargs = {\n",
    "    \"num_workers\": 32,\n",
    "    \"pin_memory\": True,\n",
    "    \"drop_last\": False,\n",
    "}\n",
    "\n",
    "train_loader = utils.get_dataloader(\n",
    "    dataset, 1, shuffle=False, **kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5200c64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_mean = torch.Tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1).cuda()\n",
    "norm_std = torch.Tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "408aed5c-98c8-4981-929b-787b51786400",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params1 = sum(p.numel() for p in generator.parameters())\n",
    "total_params2 = sum(p.numel() for p in net.parameters())\n",
    "total_params = total_params1+total_params2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4aeb77cc-574d-4cb3-9217-bb13ac727bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 115571372\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c7c5e78b-2fd7-408c-b08b-e85f8ffbd220",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianBlur(object):\n",
    "    def __init__(self, p):\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, img):\n",
    "        sigma = np.random.rand() * 1.9 + 0.1\n",
    "        return img.filter(ImageFilter.GaussianBlur(sigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3d8406a1-f25f-4591-a3bb-47b8e6db5f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import InterpolationMode\n",
    "crop = torchvision.transforms.RandomResizedCrop(224, interpolation=InterpolationMode.BICUBIC)\n",
    "color_jitter = torchvision.transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.2, hue=0.1)\n",
    "blur = torchvision.transforms.GaussianBlur(3, sigma=(0.1, 2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "026f5973-ba13-4b89-9d71-1958ccde0bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Average(lst):\n",
    "    return sum(lst) / len(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f6e10faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_list = []\n",
    "for i, (x, _, image_id, path) in enumerate(train_loader):\n",
    "    with torch.no_grad():\n",
    "        x_tf = x.cuda()\n",
    "        x_tf = x_tf * 0.5 + 0.5\n",
    "        x_tf = (x_tf - norm_mean) / norm_std\n",
    "        x_tf = torch.nn.functional.upsample(x_tf, 224, mode=\"bicubic\")\n",
    "\n",
    "        start_time = time.time()\n",
    "        # x = crop(x)\n",
    "        x_feat, _ = net(x_tf)\n",
    "        x_feat /= torch.linalg.norm(x_feat, dim=1, keepdims=True)\n",
    "\n",
    "                \n",
    "        z = torch.normal(0.0, 1.0, (x_tf.shape[0], 119)).cuda() \n",
    "\n",
    "        x_img = generator(z, None, x_feat)\n",
    "        end_time = time.time()\n",
    "\n",
    "        time_list.append(end_time-start_time)\n",
    "        if i > 100000:\n",
    "            break\n",
    "        # x = x.cpu()\n",
    "#         x_feat = x_feat.cpu()\n",
    "#         x_img = x_img.cpu()\n",
    "        \n",
    "#         for j in range(x_tf.shape[0]):\n",
    "#             folder = path[j].replace(\"imagenet\", \"ICGAN\").replace(\".JPEG\", \"\")\n",
    "#             file_name = folder.split(\"/\")[-1]\n",
    "#             test = folder + \"/\" + file_name + \".JPEG\"\n",
    "#             real_img = torch.clamp((x[j] * 0.5 + 0.5), 0, 1)\n",
    "#             torchvision.transforms.functional.to_pil_image(real_img).save(folder + \"/\" + file_name + \"_R.JPEG\")\n",
    "#             gen_img = torch.clamp((x_img[j] * 0.5 + 0.5), 0, 1)\n",
    "#             torchvision.transforms.functional.to_pil_image(gen_img).save(folder + \"/\" + file_name + \"_G.JPEG\")\n",
    "# #             torch.save(x_feat[j], folder + \"/\" + file_name + \"_F.pt\")\n",
    "        \n",
    "#     print(str((i/len(train_loader))*100.0) + \"% Done, Epoch: \" + str(i) + \"/\" + str(len(train_loader))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "158e46be-2ce3-4590-8134-8bc463472a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.019820995125105052"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Average(time_list[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ddfacacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_img = torch.clamp((x[0] * 0.5 + 0.5), 0, 1)\n",
    "# torchvision.transforms.functional.to_pil_image(input_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9342d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_img = torch.clamp((x_img * 0.5 + 0.5), 0, 1)\n",
    "# torchvision.transforms.functional.to_pil_image(x_img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c42525",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744f004f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feat_map0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7050065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d7cb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feat_map0 = torch.load(\"/Work2/Watch_This/ICGAN/ic_gan/data_utils/test_images/0_feat_map.pth\").unsqueeze(0)\n",
    "# img0 = Image.open(\"/Work2/Watch_This/ICGAN/ic_gan/data_utils/test_images/0_img.JPEG\") \n",
    "# tensor0 = torchvision.transforms.functional.to_tensor(img0).unsqueeze(0).cuda()\n",
    "# tensor0 = (tensor0 - norm_mean.cuda()) / norm_std.cuda()\n",
    "# tensor0 = torch.nn.functional.upsample(tensor0, 224, mode=\"bicubic\")\n",
    "# img0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09526170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torchvision.transforms.functional.to_pil_image(tensor0[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809388b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# z.shape, x_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85329520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_feat0, _ = net(tensor0.cuda())\n",
    "        \n",
    "# z = torch.normal(0.0, 1.0, (1, 119)).cuda() \n",
    "\n",
    "# x_img = generator(z.cuda(), None, x_feat[0:1].cuda())\n",
    "\n",
    "# x_img = torch.clamp((x_img * 0.5 + 0.5), 0, 1)\n",
    "# torchvision.transforms.functional.to_pil_image(x_img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37274716",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42019ff7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8283746",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa08eb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f71b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_img = torch.clamp((x * 0.5 + 0.5), 0, 1)\n",
    "# torchvision.transforms.functional.to_pil_image(input_img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97099d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_img = torch.clamp((x_img * 0.5 + 0.5), 0, 1)\n",
    "# torchvision.transforms.functional.to_pil_image(out_img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9d197e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ab7eef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf08c6eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b2f69b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0b6af5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9b8320",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd35f0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6054e54d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d23b380",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3570eb1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0defd09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c843b8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd43242",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab34d8ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e16a4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9562867e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce31e64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e36e9f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb731b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b21dfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2a61d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a597da3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca2700e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a674f414",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c2fcad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8442097b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ab0148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3514ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61647ba3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6515b546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if args[\"which_dataset\"] == \"imagenet\":\n",
    "#     dataset_name_prefix = \"ILSVRC\"\n",
    "#     im_prefix = \"IN\"\n",
    "# elif args[\"which_dataset\"] == \"coco\":\n",
    "#     dataset_name_prefix = \"COCO\"\n",
    "#     im_prefix = \"COCO\"\n",
    "# else:\n",
    "#     dataset_name_prefix = args[\"which_dataset\"]\n",
    "#     im_prefix = args[\"which_dataset\"]\n",
    "# # HDF5 filename\n",
    "# filename = os.path.join(\n",
    "#     args[\"data_root\"],\n",
    "#     \"%s%s_feats_%s_%s.hdf5\"\n",
    "#     % (\n",
    "#         dataset_name_prefix,\n",
    "#         args[\"resolution\"],\n",
    "#         args[\"feature_extractor\"],\n",
    "#         args[\"backbone_feature_extractor\"],\n",
    "#     ),\n",
    "# )\n",
    "# # Load features\n",
    "# print(\"Loading features %s...\" % (filename))\n",
    "# with h5.File(filename, \"r\") as f:\n",
    "#     features = f[\"feats\"][:]\n",
    "# features = np.array(features)\n",
    "# # Normalize features\n",
    "# features /= np.linalg.norm(features, axis=1, keepdims=True)\n",
    "\n",
    "# feat_dim = 2048\n",
    "# # k-means\n",
    "# print(\"Training k-means with %i centers...\" % (args[\"kmeans_subsampled\"]))\n",
    "# kmeans = faiss.Kmeans(\n",
    "#     feat_dim,\n",
    "#     args[\"kmeans_subsampled\"],\n",
    "#     niter=100,\n",
    "#     verbose=True,\n",
    "#     gpu=args[\"gpu\"],\n",
    "#     min_points_per_centroid=200,\n",
    "#     spherical=False,\n",
    "# )\n",
    "# kmeans.train(features.astype(np.float32))\n",
    "\n",
    "# # Find closest instances to each k-means cluster\n",
    "# print(\"Finding closest instances to centers...\")\n",
    "# index = faiss.IndexFlatL2(feat_dim)\n",
    "# index.add(features.astype(np.float32))\n",
    "# D, closest_sample = index.search(kmeans.centroids, 1)\n",
    "\n",
    "# net_str = (\n",
    "#     \"rn50\"\n",
    "#     if args[\"backbone_feature_extractor\"]\n",
    "#     else args[\"backbone_feature_extractor\"]\n",
    "# )\n",
    "# stored_filename = \"%s_res%i_%s_%s_kmeans_k%i\" % (\n",
    "#     im_prefix,\n",
    "#     args[\"resolution\"],\n",
    "#     net_str,\n",
    "#     args[\"feature_extractor\"],\n",
    "#     args[\"kmeans_subsampled\"],\n",
    "# )\n",
    "# np.save(\n",
    "#     os.path.join(args[\"data_root\"], stored_filename),\n",
    "#     {\"center_examples\": closest_sample},\n",
    "# )\n",
    "# print(\n",
    "#     \"Instance indexes resulting from a subsampling based on k-means have been saved in file %s!\"\n",
    "#     % (stored_filename)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0b67c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob(\"/Work1/imagenet/*/*/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b862ba6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "940000/1331167 70.61473128465474%\n",
      "950000/1331167 71.36595183023617%\n",
      "960000/1331167 72.1171723758176%\n",
      "970000/1331167 72.86839292139904%\n",
      "980000/1331167 73.61961346698047%\n",
      "990000/1331167 74.37083401256191%\n",
      "1000000/1331167 75.12205455814335%\n",
      "1010000/1331167 75.87327510372478%\n",
      "1020000/1331167 76.62449564930621%\n",
      "1030000/1331167 77.37571619488764%\n",
      "1040000/1331167 78.12693674046908%\n",
      "1050000/1331167 78.87815728605051%\n",
      "1060000/1331167 79.62937783163194%\n",
      "1070000/1331167 80.38059837721337%\n",
      "1080000/1331167 81.1318189227948%\n",
      "1090000/1331167 81.88303946837624%\n",
      "1100000/1331167 82.63426001395769%\n",
      "1110000/1331167 83.38548055953912%\n",
      "1120000/1331167 84.13670110512055%\n",
      "1130000/1331167 84.88792165070198%\n",
      "1140000/1331167 85.63914219628342%\n",
      "1150000/1331167 86.39036274186485%\n",
      "1160000/1331167 87.14158328744628%\n",
      "1170000/1331167 87.89280383302771%\n",
      "1180000/1331167 88.64402437860915%\n",
      "1190000/1331167 89.39524492419058%\n",
      "1200000/1331167 90.14646546977201%\n",
      "1210000/1331167 90.89768601535344%\n",
      "1220000/1331167 91.64890656093489%\n",
      "1230000/1331167 92.40012710651632%\n",
      "1240000/1331167 93.15134765209775%\n",
      "1250000/1331167 93.90256819767919%\n",
      "1260000/1331167 94.65378874326062%\n",
      "1270000/1331167 95.40500928884205%\n",
      "1280000/1331167 96.15622983442348%\n",
      "1290000/1331167 96.90745038000492%\n",
      "1300000/1331167 97.65867092558635%\n",
      "1310000/1331167 98.40989147116778%\n",
      "1320000/1331167 99.16111201674921%\n",
      "1330000/1331167 99.91233256233065%\n"
     ]
    }
   ],
   "source": [
    "for ind, file in enumerate(files):\n",
    "    if ind < 940000: continue\n",
    "    im = Image.open(file).convert(\"RGB\") \n",
    "    folder = file.replace(\"imagenet\", \"ICGAN\").replace(\".JPEG\", \"\")\n",
    "    file_name = file.split(\"/\")[-1].replace(\".JPEG\", \"\")\n",
    "    im.save(folder + \"/\" + file_name + \"_R.JPEG\")\n",
    "    if ind % 10000 == 0:\n",
    "        print(str(ind) + \"/\" + str(len(files)) + \" \" + str((ind/len(files))*100) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b17858",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
